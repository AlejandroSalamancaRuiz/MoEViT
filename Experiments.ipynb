{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=0\n"
     ]
    }
   ],
   "source": [
    "from Utils import split_dataset_casia_wf, create_data_loader, slplit_dataset_digi_face\n",
    "from MoEViT import MoEViT, MoEViTConfig\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "#from SigleDeviceTraining import train\n",
    "torch.cuda.empty_cache()\n",
    "%env CUDA_LAUNCH_BLOCKING=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split_dataset_casi_wf(base_folder='casia-web-face-dataset', validation_percentage=0.15, num_identification_imgs=500)\n",
    "#slplit_dataset_digi_face(base_folder='Digi-Face', validation_percentage=0.1, num_identification_imgs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_data_loader('data/data_t/train', 112, 10)\n",
    "\n",
    "val_loader = create_data_loader('data/data_t/validation', 112, 10)\n",
    "\n",
    "id_imgs_loader = create_data_loader('data/casia-web-face-dataset/identification_imgs', 112, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─ModuleDict: 1-1                        --\n",
       "|    └─Conv2d: 2-1                       113,664\n",
       "|    └─Dropout: 2-2                      --\n",
       "|    └─ModuleList: 2-3                   --\n",
       "|    |    └─EncoderBlock: 3-1            30,091,788\n",
       "|    |    └─EncoderBlock: 3-2            30,091,788\n",
       "|    |    └─EncoderBlock: 3-3            30,091,788\n",
       "|    |    └─EncoderBlock: 3-4            30,091,788\n",
       "|    |    └─EncoderBlock: 3-5            30,091,788\n",
       "|    |    └─EncoderBlock: 3-6            30,091,788\n",
       "|    |    └─EncoderBlock: 3-7            30,091,788\n",
       "|    |    └─EncoderBlock: 3-8            30,091,788\n",
       "|    |    └─EncoderBlock: 3-9            30,091,788\n",
       "|    |    └─EncoderBlock: 3-10           30,091,788\n",
       "|    |    └─EncoderBlock: 3-11           30,091,788\n",
       "|    |    └─EncoderBlock: 3-12           30,091,788\n",
       "|    └─RMSNorm: 2-4                      768\n",
       "├─Linear: 1-2                            590,592\n",
       "├─Linear: 1-3                            7,680,000\n",
       "=================================================================\n",
       "Total params: 369,486,480\n",
       "Trainable params: 369,486,480\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_device = 'cuda'\n",
    "\n",
    "config = MoEViTConfig(device=current_device)\n",
    "\n",
    "model = MoEViT(config)\n",
    "model.to(current_device)\n",
    "\n",
    "summary(model, input_size = (3, 112, 112), batch_size = 8, device='cuda', verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'MoEViTConfig' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m config:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(a)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'MoEViTConfig' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "for a in config:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "wd = 0.01\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(32, 3, 112, 112).to(current_device)  # Batch size of 32, input size of 784\n",
    "labels = torch.randint(0, config.num_classes, (32,)).to(current_device)  # Random labels for a batch of 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], profile_memory=True, record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        images = inputs\n",
    "        labels = labels\n",
    "        logits, embeddings, loss = model(images, labels)\n",
    "        optimizer.zero_grad()\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Optimizing weights\n",
    "        optimizer.step()\n",
    "        # outputs = model(inputs)  # Forward pass\n",
    "        # loss = criterion(outputs, labels)\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()  # Backward pass\n",
    "        # optimizer.step()\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_loader, val_loader, id_imgs_loader, 2, optimizer, 6, 'cuda', 'test_cp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ads\n",
    "from ads.common.auth import default_signer\n",
    "\n",
    "ads.set_auth(auth='resource_principal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import math\n",
    "import oci\n",
    "\n",
    "# Initialize a Resource Principals provider\n",
    "auth_provider = oci.auth.signers.get_resource_principals_signer()\n",
    "\n",
    "# Create an Object Storage client\n",
    "object_storage_client = oci.object_storage.ObjectStorageClient({}, signer=auth_provider)\n",
    "\n",
    "# Get the object\n",
    "response = object_storage_client.get_object('lr1qux0xfjaq', 'bucket-casia-webface', 'casia-webface.zip')\n",
    "\n",
    "# Save the object data to a file\n",
    "with open('data', 'wb') as file:\n",
    "    for chunk in response.data.raw.stream(1024 * 1024, decode_content=False):\n",
    "        file.write(chunk)\n",
    "#print(f\"Downloaded {object_name} from bucket {bucket_name} to {download_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "path = f\"data\"\n",
    "extract_to = 'data_unzip'\n",
    "\n",
    "try:\n",
    "    with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "        print(f\"Extracted all files to {extract_to}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {path} was not found.\")\n",
    "except zipfile.BadZipFile:\n",
    "    print(f\"Error: The file {path} is not a zip file or it is corrupted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def count_files_in_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Counts the number of files in a directory and its subdirectories.\n",
    "    \n",
    "    Parameters:\n",
    "    directory_path (str): Path to the directory.\n",
    "    \n",
    "    Returns:\n",
    "    int: Number of files in the directory and its subdirectories.\n",
    "    \"\"\"\n",
    "    file_count = 0\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        file_count += len(files)\n",
    "    return file_count\n",
    "\n",
    "# Example usage\n",
    "directory_path = 'data_unzip'\n",
    "number_of_files = count_files_in_directory(directory_path)\n",
    "print(f\"Number of files in '{directory_path}' and its subdirectories: {number_of_files}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
